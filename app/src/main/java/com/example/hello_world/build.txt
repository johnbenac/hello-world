 
```AssistantViewModel.kt``` 
 
package com.example.hello_world 
(additional import statements abridged) 
class AssistantViewModel( 
    private val textToSpeechServiceState: MutableState<TextToSpeechService>, 
    private val context: Context, 
    private val settingsViewModel: SettingsViewModel, 
    private val openAiApiService: OpenAiApiService 
) : ViewModel() { 
    private val audioFilePathState = mutableStateOf<String>("") // Add this line 
    //    private val openAiApiService = OpenAiApiService("your_api_key_here", settingsViewModel) 
    val latestPartialResult = mutableStateOf<String?>(null) 
    val _isAssistantSpeaking = mutableStateOf(false) 
    val mediaPlaybackManager: MediaPlaybackManager = AndroidMediaPlaybackManager() 
    val isAssistantSpeaking: Boolean get() = _isAssistantSpeaking.value 
    //    val shouldListenAfterSpeaking = mutableStateOf(true) 
    private val mainHandler = Handler(Looper.getMainLooper()) 
    val voiceTriggerDetector = VoiceTriggerDetector(context, "Hey", this::onTriggerWordDetected, mainHandler, this.latestPartialResult) 
    private val _conversationMessages = mutableStateListOf<ConversationMessage>() 
    val conversationMessages: List<ConversationMessage> get() = _conversationMessages 
    private val _isListening = mutableStateOf(false) 
    val isListening: Boolean get() = _isListening.value 
    fun startListening() { 
        voiceTriggerDetector.startListening() 
        _isListening.value = true 
//        Log.d("AssistantViewModel", "log: startListening called 1") 
    } 
    private suspend fun sendUserMessageToOpenAi(userMessage: String) { 
        // Add user message to the conversation state 
        _conversationMessages.add(ConversationMessage("User", userMessage, audioFilePathState)) 
        val responseText = openAiApiService.sendMessage(_conversationMessages) 
        Log.d("AssistantViewModel", "Received response from OpenAI API: $responseText") 
        onAssistantResponse(responseText, audioFilePathState) 
        textToSpeechServiceState.value.speak(responseText.replace("\n", " "), onFinish = { 
            mainHandler.post { 
                _isAssistantSpeaking.value = false 
//                if (_isListening.value) { 
                startListening() 
                Log.d("AssistantViewModel", "log: startListening called 2") 
//                } 
            } 
        }, onStart = { 
            mainHandler.post { 
                stopListening() 
                Log.d("AssistantViewModel", "log: stopListening called 1") 
            } 
        }, audioFilePathState = audioFilePathState) 
        _isAssistantSpeaking.value = true 
    } 
    private fun startPeriodicListeningCheck() { 
        mainHandler.postDelayed({ 
            if (_isListening.value && _isAssistantSpeaking.value) { 
//                Log.d("AssistantViewModel", "log: Periodic check - Restarting listening") 
                startListening() 
            } 
            startPeriodicListeningCheck() 
        }, 3000) // Check every 3 seconds 
    } 
    private fun onAssistantResponse(response: String, audioFilePathState: MutableState<String>) { 
        Log.d("AssistantViewModel", "log: onAssistantResponse called") 
        // Add assistant message to the conversation state 
        _conversationMessages.add(ConversationMessage("Assistant", response, audioFilePathState)) 
        Log.d("AssistantViewModel", "log: _conversationMessages added") 
    } 
    fun stopListening() { 
        voiceTriggerDetector.stopListening() 
        Log.d("AssistantViewModel", "log: stopListening called 2") 
        _isListening.value = false 
    } 
    fun onTriggerWordDetected(userMessage: String) { // Add userMessage parameter 
        // Add user message to the conversation state 
        Log.d("AssistantViewModel", "log: onTriggerWordDetected called") 
        // Stop listening 
        voiceTriggerDetector.stopListening() // Replace stopListeningForever() with stopListening() 
        Log.d("AssistantViewModel", "log: stopListening called 3") 
        // Send the user message to OpenAI API and process the response 
        viewModelScope.launch { 
            sendUserMessageToOpenAi(userMessage) // Pass the userMessage parameter here 
        } 
    } 
    init { 
        startPeriodicListeningCheck() 
    } 
} 
 
```ConversationMessage.kt``` 
 
(additional import statements abridged) 
data class ConversationMessage( 
    val sender: String, 
    val message: String, 
    val audioFilePath: MutableState<String> 
) 
 
```MainActivity.kt``` 
 
package com.example.hello_world 
(additional import statements abridged) 
class MainActivity : AppCompatActivity() { 
    private var textToSpeechService: TextToSpeechService? = null 
    private lateinit var voiceTriggerDetector: VoiceTriggerDetector 
    private lateinit var openAiApiService: OpenAiApiService 
    private val RECORD_AUDIO_PERMISSION_REQUEST_CODE = 1 
    private val settingsViewModel = SettingsViewModel() 
    private lateinit var assistantViewModel: AssistantViewModel 
    override fun onCreate(savedInstanceState: Bundle?) { 
//        val textToSpeechServiceState = mutableStateOf<TextToSpeechService>(AndroidTextToSpeechService(this)) 
//        assistantViewModel = AssistantViewModel(textToSpeechServiceState, this, settingsViewModel, openAiApiService) 
        super.onCreate(savedInstanceState) 
        Log.d("MainActivity", "log: MainActivity opened") 
        // Request audio recording permission 
        requestAudioPermission() 
        // Initialize the TextToSpeechService state 
        val textToSpeechServiceState = mutableStateOf<TextToSpeechService>(AndroidTextToSpeechService(this)) 
        openAiApiService = OpenAiApiService("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", settingsViewModel) 
        assistantViewModel = AssistantViewModel(textToSpeechServiceState, this, settingsViewModel, openAiApiService) 
        voiceTriggerDetector = assistantViewModel.voiceTriggerDetector 
        setContent { 
            val navController = rememberNavController() 
            NavHost(navController, startDestination = "assistant") { 
                composable("assistant") { 
                    AssistantScreen(assistantViewModel, settingsViewModel, { navController.navigate("settings") }, textToSpeechServiceState) 
                } 
                composable("settings") { 
                    SettingsScreen(settingsViewModel, { navController.popBackStack() }, navController) 
                } 
                composable("edit-settings") { 
                    EditSettingsScreen(settingsViewModel, { navController.popBackStack() }, { navController.popBackStack() }) 
                } 
            } 
        } 
    } 
    private fun requestAudioPermission() { 
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) == PackageManager.PERMISSION_GRANTED) { 
            ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.RECORD_AUDIO), RECORD_AUDIO_PERMISSION_REQUEST_CODE) 
        } 
    } 
    override fun onResume() { 
        super.onResume() 
        voiceTriggerDetector.startListening() 
    } 
    override fun onPause() { 
        super.onPause() 
        textToSpeechService?.stop() // Stop any ongoing speech 
    } 
    override fun onDestroy() { 
        super.onDestroy() 
        textToSpeechService?.shutdown() 
    } 
    private val conversationMessages = mutableStateListOf<ConversationMessage>() 
    override fun onRequestPermissionsResult(requestCode: Int, permissions: Array<out String>, grantResults: IntArray) { 
        super.onRequestPermissionsResult(requestCode, permissions, grantResults) 
        if (requestCode == RECORD_AUDIO_PERMISSION_REQUEST_CODE) { 
            if (grantResults.isNotEmpty() && grantResults[0] == PackageManager.PERMISSION_GRANTED) { 
                // Permission was granted 
                // Continue with creating the app UI and setting up listeners 
            } else { 
                // Permission was denied 
                // Show a message to the user and close the app 
                Toast.makeText(this, "Permission to record audio is required to use this app.", Toast.LENGTH_LONG).show() 
                finish() 
            } 
        } 
    } 
} 
//@Composable 
//fun ConversationScreen(messages: List<ConversationMessage>, assistantViewModel: AssistantViewModel, context: Context) { 
//    val listState = rememberLazyListState() 
// 
//    LaunchedEffect(messages.size) { 
//        if (messages.isNotEmpty()) { 
//            listState.animateScrollToItem(messages.size - 1) 
//        } 
//    } 
// 
//    LazyColumn(state = listState) { 
//        items(messages) { message -> 
//            MessageCard(message) { audioFilePath -> 
//                assistantViewModel.mediaPlaybackManager.playAudio(audioFilePath, context) 
//            } 
//        } 
//    } 
//} 
@Composable 
fun MediaControls( 
    onPlay: () -> Unit, 
    onPause: () -> Unit, 
    onSeekForward: () -> Unit, 
    onSeekBackward: () -> Unit 
) { 
    Row { 
        IconButton(onClick = onPlay) { 
            Icon(Icons.Filled.PlayArrow, contentDescription = "Play") 
        } 
        IconButton(onClick = onPause) { 
            Icon(Icons.Filled.AccountBox, contentDescription = "Pause") 
        } 
        IconButton(onClick = onSeekForward) { 
            Icon(Icons.Filled.KeyboardArrowRight, contentDescription = "Seek Forward") 
        } 
        IconButton(onClick = onSeekBackward) { 
            Icon(Icons.Filled.KeyboardArrowLeft, contentDescription = "Seek Backward") 
        } 
    } 
} 
@Composable 
fun MessageCard( 
    message: ConversationMessage, 
    onPlayAudio: (String) -> Unit 
) { 
    Log.d("MessageCard", "Message: $message") 
    Card( 
        modifier = Modifier 
            .padding(8.dp) 
            .fillMaxWidth() 
    ) { 
        Column( 
            modifier = Modifier 
                .padding(16.dp) 
        ) { 
            Text(text = message.sender, fontWeight = FontWeight.Bold) 
            Spacer(modifier = Modifier.height(4.dp)) 
            Text(text = message.message) 
            Spacer(modifier = Modifier.height(8.dp)) 
            MediaControls( 
                onPlay = { 
                    Log.d("MessageCard", "Playing audio from file: ${message.audioFilePath.value}") // Add this line 
                    onPlayAudio(message.audioFilePath.value) 
                }, 
                onPause = { /* Implement pause functionality in AssistantViewModel and pass the callback here */ }, 
                onSeekForward = { /* Implement seek forward functionality in AssistantViewModel and pass the callback here */ }, 
                onSeekBackward = { /* Implement seek backward functionality in AssistantViewModel and pass the callback here */ } 
            ) 
        } 
    } 
} 
@Composable 
fun AssistantScreen( 
    assistantViewModel: AssistantViewModel, 
    settingsViewModel: SettingsViewModel, 
    onSettingsClicked: () -> Unit, 
    textToSpeechServiceState: MutableState<TextToSpeechService> 
) { 
    val context = LocalContext.current // Get the current context 
    // ... 
    BoxWithConstraints( 
        modifier = Modifier 
            .fillMaxSize() 
            .padding(16.dp) 
    ) { 
        val maxHeight = constraints.maxHeight 
        Column(modifier = Modifier.fillMaxSize()) { 
            LazyColumn( 
                modifier = Modifier 
                    .weight(1f) 
                    .height(((maxHeight.dp - 64.dp).coerceAtLeast(0.dp))) 
            ) { 
                items(assistantViewModel.conversationMessages) { message -> 
                    MessageCard(message) { audioFilePath -> 
                        assistantViewModel.mediaPlaybackManager.playAudio(audioFilePath, context) 
                    } 
                } 
            } 
            Spacer(modifier = Modifier.height(16.dp)) 
            Text( 
                text = if (assistantViewModel.isListening) "Listening..." else "Not Listening", // Use assistantViewModel.isListening here 
                modifier = Modifier.align(Alignment.CenterHorizontally) 
            ) // Add this line to show the listening status 
            Spacer(modifier = Modifier.height(16.dp)) 
            Button( 
                onClick = { 
                    if (textToSpeechServiceState.value is AndroidTextToSpeechService) { 
                        textToSpeechServiceState.value = ElevenLabsTextToSpeechService("82b94d982c1018cb379c0acb629d473c", "TxGEqnHWrfWFTfGW9XjX", context) // Pass the context here 
                    } else { 
                        textToSpeechServiceState.value = AndroidTextToSpeechService(context) // Pass the context here 
                    } 
                }, 
                modifier = Modifier.align(Alignment.CenterHorizontally) 
            ) { 
                Text(if (textToSpeechServiceState.value is AndroidTextToSpeechService) "Use Eleven Labs TTS" else "Use Google TTS") 
            } 
            Button( 
                onClick = { 
                    if (assistantViewModel.isListening) { // Use assistantViewModel.isListening here 
                        Log.d("MainActivity", "Stop Listening button clicked") 
                        assistantViewModel.stopListening() 
                    } else { 
                        Log.d("MainActivity", "Start Listening button clicked") 
                        assistantViewModel.startListening() 
                    } 
                }, 
                modifier = Modifier.align(Alignment.CenterHorizontally) 
            ) { 
                Text(if (assistantViewModel.isListening) "Stop Listening" else "Start Listening") // Use assistantViewModel.isListening here 
            } 
            Button( 
                onClick = onSettingsClicked, 
                modifier = Modifier.align(Alignment.CenterHorizontally) 
            ) { 
                Text("Settings") 
            } 
        } 
    } 
} 
 
```TextToSpeechService.kt``` 
 
package com.example.hello_world 
(additional import statements abridged) 
interface TextToSpeechService { 
    fun speak(text: String, onFinish: (() -> Unit)?, onStart: (() -> Unit)?, audioFilePathState: MutableState<String>): String 
    fun stop() 
    fun getAudioFilePath(): String 
    fun shutdown() 
} 
 
