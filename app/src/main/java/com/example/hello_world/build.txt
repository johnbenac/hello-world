You are a senior app developer, helping me, a junior apprentice coder. We are working together on debugging an app that listens for a trigger word, and then transcribes the audio recorded. This is the code of the app: 
```AndroidTextToSpeechService.kt``` 
package com.example.hello_world
import android.content.Context
import android.speech.tts.TextToSpeech
import java.util.UUID
import android.speech.tts.UtteranceProgressListener
import java.util.Locale

class AndroidTextToSpeechService(private val context: Context) : TextToSpeechService, TextToSpeech.OnInitListener {
    private var textToSpeech: TextToSpeech = TextToSpeech(context, this)

    override fun onInit(status: Int) {
        if (status == TextToSpeech.SUCCESS) {
            val result = textToSpeech.setLanguage(Locale.getDefault())
            if (result == TextToSpeech.LANG_MISSING_DATA || result == TextToSpeech.LANG_NOT_SUPPORTED) {
                // Handle the case where the default language data or the language itself is not supported
            }
        } else {
            // Handle the case where TextToSpeech initialization failed
        }
    }

    override fun speak(text: String, onFinish: (() -> Unit)?) {
        val utteranceId = UUID.randomUUID().toString()
        textToSpeech.setOnUtteranceProgressListener(object : UtteranceProgressListener() {
            override fun onStart(utteranceId: String) {}

            override fun onDone(utteranceId: String) {
                onFinish?.invoke()
            }

            override fun onError(utteranceId: String) {}
        })

        textToSpeech.speak(text, TextToSpeech.QUEUE_FLUSH, null, utteranceId)
    }


    override fun stop() {
        textToSpeech.stop()
    }

    override fun shutdown() {
        textToSpeech.shutdown()
    }
}``` 
```AssistantViewModel.kt``` 
package com.example.hello_world
import android.content.Context
import androidx.compose.runtime.mutableStateListOf
import androidx.compose.runtime.mutableStateOf
import androidx.lifecycle.ViewModel
import android.util.Log
import android.os.Handler
import android.os.Looper
import androidx.lifecycle.viewModelScope
import kotlinx.coroutines.launch


class AssistantViewModel(
    private val textToSpeechService: TextToSpeechService,
    private val context: Context,
    private val openAiApiService: OpenAiApiService
) : ViewModel() {
    val latestPartialResult = mutableStateOf("")  // Add it here


    private val voiceTriggerDetector = VoiceTriggerDetector(context, "Hey", this::onTriggerWordDetected, latestPartialResult = this.latestPartialResult)

    private val _conversationMessages = mutableStateListOf<ConversationMessage>()
    val conversationMessages: List<ConversationMessage> get() = _conversationMessages

    private val _isListening = mutableStateOf(false)
    val isListening: Boolean get() = _isListening.value

    fun startListening() {
//        voiceTriggerDetector.startListening()
        voiceTriggerDetector.startListening()
        _isListening.value = true
    }

    private suspend fun sendUserMessageToOpenAi(userMessage: String) {
        val responseText = openAiApiService.sendMessage(userMessage)
        onAssistantResponse(responseText)
        textToSpeechService.speak(responseText) {
            Handler(Looper.getMainLooper()).post {
                voiceTriggerDetector.startListening()
            }
        }
    }

    fun stopListening() {
//        voiceTriggerDetector.stopListening()
        voiceTriggerDetector.stopListening()
        _isListening.value = false
    }

    fun onTriggerWordDetected() {
        // Add user message to the conversation state
        _conversationMessages.add(ConversationMessage("User", "Trigger Word"))
        Log.d("AssistantViewModel", "log: onTriggerWordDetected called")
    
        // Stop listening
        voiceTriggerDetector.stopListeningForever()
    
        // Handle trigger word detection, for example, call textToSpeechService.speak("Response text")
        textToSpeechService.speak("Response text") {
            // Run startListening() on the main thread
            Handler(Looper.getMainLooper()).post {
                voiceTriggerDetector.startListening()
            }
        }
    
        // Get the transcription of the message received after the trigger word
        val userMessage = "Transcription of the message received after the trigger word"
    
        // Send the user message to OpenAI API and process the response
        viewModelScope.launch {
            sendUserMessageToOpenAi(userMessage)
        }
    }

    fun onAssistantResponse(response: String) {
        // Add assistant message to the conversation state
        _conversationMessages.add(ConversationMessage("Assistant", response))
    }
}``` 
```ConversationMessage.kt``` 
package com.example.hello_world

data class ConversationMessage(val sender: String, val message: String)``` 
```MainActivity.kt``` 
package com.example.hello_world
import android.Manifest
import android.content.pm.PackageManager
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import androidx.appcompat.app.AppCompatActivity
import android.os.Bundle
import android.util.Log
import android.widget.Toast
import androidx.activity.compose.setContent
import androidx.compose.foundation.layout.Column
import androidx.compose.foundation.layout.fillMaxSize
import androidx.compose.foundation.layout.height
import androidx.compose.foundation.layout.padding
import androidx.compose.foundation.lazy.LazyColumn
import androidx.compose.foundation.lazy.items
import androidx.compose.runtime.Composable
import androidx.compose.runtime.mutableStateListOf
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.foundation.layout.Spacer
import androidx.compose.foundation.layout.fillMaxWidth
import androidx.compose.material3.Button
import androidx.compose.material3.Card
import androidx.compose.material3.Text
import androidx.compose.ui.text.font.FontWeight
import androidx.compose.ui.unit.dp



// data class ConversationMessage(val sender: String, val message: String)

class MainActivity : AppCompatActivity() {
    private lateinit var textToSpeechService: TextToSpeechService
    private lateinit var assistantViewModel: AssistantViewModel
    private lateinit var voiceTriggerDetector: VoiceTriggerDetector
    private lateinit var openAiApiService: OpenAiApiService
    private val RECORD_AUDIO_PERMISSION_REQUEST_CODE = 1

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        Log.d("MainActivity", "log: MainActivity opened")

        // Request audio recording permission
        requestAudioPermission()

        textToSpeechService = AndroidTextToSpeechService(this)
        openAiApiService = OpenAiApiService("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")
        assistantViewModel = AssistantViewModel(textToSpeechService, this, openAiApiService)
        voiceTriggerDetector = VoiceTriggerDetector(this, "Hey", assistantViewModel::onTriggerWordDetected)

        setContent {
            AssistantScreen(assistantViewModel)
        }
    }

    private fun requestAudioPermission() {
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED) {
            ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.RECORD_AUDIO), RECORD_AUDIO_PERMISSION_REQUEST_CODE)
        }
    }

    override fun onResume() {
        super.onResume()
        voiceTriggerDetector.startListening()
    }

    override fun onPause() {
        super.onPause()
        voiceTriggerDetector.stopListening()
        textToSpeechService.stop() // Stop any ongoing speech
    }

    override fun onDestroy() {
        super.onDestroy()
        textToSpeechService.shutdown()
    }

    private val conversationMessages = mutableStateListOf<ConversationMessage>()

//    private fun onAssistantResponse(response: String) {
//        // Add assistant message to the conversation state
//        conversationMessages.add(ConversationMessage("Assistant", response))
//        assistantViewModel.onAssistantResponse(response)
//    }

    override fun onRequestPermissionsResult(requestCode: Int, permissions: Array<out String>, grantResults: IntArray) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == RECORD_AUDIO_PERMISSION_REQUEST_CODE) {
            if (grantResults.isNotEmpty() && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                // Permission was granted
                // Continue with creating the app UI and setting up listeners
                setContent {
                    AssistantScreen(assistantViewModel)
                }
            } else {
                // Permission was denied
                // Show a message to the user and close the app
                Toast.makeText(this, "Permission to record audio is required to use this app.", Toast.LENGTH_LONG).show()
                finish()
            }
        }
    }
}

@Composable
fun ConversationScreen(messages: List<ConversationMessage>) {
    LazyColumn {
        items(messages) { message ->
            MessageCard(message)
        }
    }
}

@Composable
fun MessageCard(message: ConversationMessage) {
    Card(
        modifier = Modifier
            .padding(8.dp)
            .fillMaxWidth()
    ) {
        Column(
            modifier = Modifier
                .padding(16.dp)
        ) {
            Text(text = message.sender, fontWeight = FontWeight.Bold)
            Spacer(modifier = Modifier.height(4.dp))
            Text(text = message.message)
        }
    }
}

@Composable
fun AssistantScreen(assistantViewModel: AssistantViewModel) {
    val conversationMessages = assistantViewModel.conversationMessages
    val isListening = assistantViewModel.isListening


    Column(
        modifier = Modifier
            .fillMaxSize()
            .padding(16.dp)
    ) {
        ConversationScreen(messages = conversationMessages)

        Spacer(modifier = Modifier.height(16.dp))

        Button(
            onClick = {
                if (isListening) {
                    assistantViewModel.stopListening()
                } else {
                    assistantViewModel.startListening()
                }
            },
            modifier = Modifier.align(Alignment.CenterHorizontally)
        ) {
            Text(if (isListening) "Stop Listening" else "Start Listening")
        }
    }
}``` 
```OpenAiApiResponse.kt``` 
package com.example.hello_world
import com.example.hello_world.OpenAiApiResponse

data class OpenAiApiResponse(val choices: List<OpenAiApiChoice>)

data class OpenAiApiChoice(val text: String)``` 
```OpenAiApiService.kt``` 
package com.example.hello_world
import android.util.Log
import okhttp3.Call
import okhttp3.Callback
import okhttp3.Response
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.OkHttpClient
import okhttp3.Request
import okhttp3.RequestBody.Companion.toRequestBody
import com.squareup.moshi.Moshi
import com.squareup.moshi.kotlin.reflect.KotlinJsonAdapterFactory
import kotlinx.coroutines.suspendCancellableCoroutine
import java.io.IOException
import kotlin.coroutines.resumeWithException
import kotlin.coroutines.suspendCoroutine

data class OpenAiMessage(val role: String, val content: String)

data class OpenAiApiRequest(
    val messages: List<OpenAiMessage>,
    val temperature: Double,
    val max_tokens: Int,
    val top_p: Int,
    val frequency_penalty: Double,
    val presence_penalty: Double,
    val model: String,
    val stream: Boolean
)

class OpenAiApiService(private val apiKey: String) {
    private val client = OkHttpClient()
    private val moshi = Moshi.Builder().add(KotlinJsonAdapterFactory()).build()

    suspend fun sendMessage(userMessage: String): String = suspendCancellableCoroutine { continuation ->
        val messages = listOf(
            OpenAiMessage("system", "you are an ai assistant named jake"),
            OpenAiMessage("user", userMessage)
        )
    
        val requestJson = moshi.adapter(OpenAiApiRequest::class.java).toJson(
            OpenAiApiRequest(
                messages = messages,
                temperature = 0.9,
                max_tokens = 6,
                top_p = 1,
                frequency_penalty = 0.0,
                presence_penalty = 0.6,
                model = "gpt-4",
                stream = true
            )
        )
        Log.d("OpenAiApiService", "API Request: $requestJson")
    
        val requestBody = requestJson.toRequestBody("application/json; charset=utf-8".toMediaType())
    
        val request = Request.Builder()
            .url("https://api.openai.com/v1/chat/completions")
            .addHeader("Authorization", "Bearer $apiKey")
            .post(requestBody)
            .build()
    
        val call = client.newCall(request)
    
        call.enqueue(object : Callback {
            override fun onFailure(call: Call, e: IOException) {
                if (continuation.isCancelled) return
                continuation.resumeWithException(e)
            }
    
            override fun onResponse(call: Call, response: Response) {
                if (continuation.isCancelled) return
    
                if (!response.isSuccessful) {
                    continuation.resumeWithException(IOException("Unexpected code $response"))
                } else {
                    val responseBody = response.body?.string()
                    val jsonAdapter = moshi.adapter(OpenAiApiResponse::class.java)
                    val apiResponse = jsonAdapter.fromJson(responseBody)
    
                    continuation.resumeWith(Result.success(apiResponse?.choices?.firstOrNull()?.text ?: ""))
                }
            }
        })
    }
}``` 
```TextToSpeechService.kt``` 
package com.example.hello_world

interface TextToSpeechService {
    fun speak(text: String, onFinish: (() -> Unit)? = null)
    fun stop()
    fun shutdown()
}``` 
```VoiceTriggerDetector.kt``` 
package com.example.hello_world
import android.content.Context
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.content.Intent
import android.os.Bundle
import android.util.Log
import android.os.Handler
import android.os.Looper
import androidx.compose.runtime.MutableState


class VoiceTriggerDetector(
    private val context: Context,
    private val triggerWord: String,
    private val onTriggerWordDetected: (() -> Unit),
    private val mainHandler: Handler = Handler(Looper.getMainLooper()),
    private val latestPartialResult: MutableState<String> // Add this line
) : RecognitionListener {
    private val speechRecognizer: SpeechRecognizer = SpeechRecognizer.createSpeechRecognizer(context)
    private var keepListening: Boolean = true

    init {
        speechRecognizer.setRecognitionListener(this)
    }

    fun startListening() {
        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_CALLING_PACKAGE, context.packageName)
            putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, true)
        }
        speechRecognizer.startListening(intent)
    }

    fun stopListening() {
        speechRecognizer.stopListening()
    }

    fun stopListeningForever() {
        keepListening = false
        stopListening()
    }

    override fun onReadyForSpeech(params: Bundle) {
        // Handle when the SpeechRecognizer is ready to receive speech input
    }

    override fun onBeginningOfSpeech() {
        // Handle when the user starts speaking
    }

    override fun onRmsChanged(rmsdB: Float) {
        // Handle changes in the received sound level (RMS)
    }

    override fun onBufferReceived(buffer: ByteArray) {
        // Handle more sound data being available
    }

    override fun onEndOfSpeech() {
        // Handle when the user stops speaking
    }

    override fun onError(error: Int) {
        // Handle errors that may occur during speech recognition
    }

    override fun onResults(results: Bundle) {
        val matches = results.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
        Log.d("VoiceTriggerDetector", "Final Results: $matches")
        matches?.let { processResults(it) }
    
        // Restart listening if the trigger word is not detected and the flag is set to keep listening
        if (keepListening) {
            mainHandler.post { startListening() }
        }
    }

    override fun onPartialResults(partialResults: Bundle) {
        val matches = partialResults.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
        Log.d("VoiceTriggerDetector", "Partial Results: $matches")
        matches?.let { processResults(it) }
    
        // Restart listening if the trigger word is not detected and the flag is set to keep listening
        if (keepListening) {
            mainHandler.post { startListening() }
        }
    }

    override fun onEvent(eventType: Int, params: Bundle) {
        // Handle any events that may occur during speech recognition
    }



    private fun processResults(matches: ArrayList<String>) {
        for (result in matches) {
            if (result.contains(triggerWord, ignoreCase = true)) {
                // Trigger word detected, handle the event here
                Log.d("VoiceTriggerDetector", "log: Trigger word detected")
                onTriggerWordDetected() // Call the callback function
                break
            }
        }
    }
}``` 
