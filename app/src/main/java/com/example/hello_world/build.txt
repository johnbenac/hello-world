You are a senior app developer, helping me, a junior apprentice coder. We are working together on building an alpha build iteratively into a minimum viable product. The app uses the phone microphone to listen to the user, sends their messages to openAI chat API endpoint probably using a trigger word) and then do an audio playback of the response from openAI: 
 
```AndroidMediaPlaybackManager.kt``` 
 

package com.example.hello_world

import android.content.Context
import android.media.MediaPlayer
import android.util.Log
import android.widget.MediaController

class AndroidMediaPlaybackManager : MediaPlaybackManager {
    private var mediaPlayer: MediaPlayer? = null
    private var mediaController: MediaController? = null
    override fun playAudio(filePath: String, context: Context) {
        mediaPlayer?.release()
        mediaPlayer = MediaPlayer().apply {
            Log.d("AndroidMediaPlaybackManager", "Playing audio from file: $filePath") // Add this line
            setDataSource(filePath)
            prepare()
            start()
        }
        mediaController?.hide()
        mediaController = MediaController(context)
        mediaController?.setMediaPlayer(object : MediaController.MediaPlayerControl {
            override fun start() = mediaPlayer?.start() ?: Unit
            override fun pause() = mediaPlayer?.pause() ?: Unit
            // Implement other required methods
            override fun getDuration(): Int = mediaPlayer?.duration ?: 0
            override fun getCurrentPosition(): Int = mediaPlayer?.currentPosition ?: 0
            override fun getBufferPercentage(): Int = 0
            override fun isPlaying(): Boolean = mediaPlayer?.isPlaying ?: false
            override fun seekTo(position: Int) {
                mediaPlayer?.seekTo(position)
            }
            override fun canPause(): Boolean {
                // Return true if your media player can pause, otherwise return false
                return true
            }
            override fun getAudioSessionId(): Int {
                // Return the audio session ID of your media player or 0 if not available
                return mediaPlayer?.audioSessionId ?: 0
            }
            override fun canSeekBackward(): Boolean {
                // Return true if your media player can seek backward, otherwise return false
                return true
            }
            override fun canSeekForward(): Boolean {
                // Return true if your media player can seek forward, otherwise return false
                return true
            }
        })
        mediaController?.show()
    }
}
 
``` 
 
 
```AndroidTextToSpeechService.kt``` 
 
package com.example.hello_world
import android.content.Context
import android.speech.tts.TextToSpeech
import java.util.UUID
import android.speech.tts.UtteranceProgressListener
import android.util.Log
import androidx.compose.runtime.MutableState
import java.io.File
import java.util.Locale



class AndroidTextToSpeechService(private val context: Context) : TextToSpeechService, TextToSpeech.OnInitListener {
    private var lastGeneratedAudioFilePath: String? = null
    private var textToSpeech: TextToSpeech = TextToSpeech(context, this)
    override fun onInit(status: Int) {
        if (status == TextToSpeech.SUCCESS) {
            val result = textToSpeech.setLanguage(Locale.getDefault())
            if (result == TextToSpeech.LANG_MISSING_DATA || result == TextToSpeech.LANG_NOT_SUPPORTED) {
                // Handle the case where the default language data or the language itself is not supported
            }
        } else {
            // Handle the case where TextToSpeech initialization failed
        }
    }

    override fun speak(text: String, onFinish: (() -> Unit)?, onStart: (() -> Unit)?, audioFilePathState: MutableState<String>): String {
        val utteranceId = UUID.randomUUID().toString()
        Log.d("AndroidTextToSpeechService", "synthesizeToFile called with utteranceId: $utteranceId")
        val uniqueFileName = "google_tts_${UUID.randomUUID()}.mp3"
        val filePath = File(context.getExternalFilesDir(null), uniqueFileName).absolutePath

        textToSpeech.synthesizeToFile(text, null, File(filePath), UUID.randomUUID().toString())
        textToSpeech.setOnUtteranceProgressListener(object : UtteranceProgressListener() {
            override fun onStart(utteranceId: String) {
                onStart?.invoke()
                Log.d("AndroidTextToSpeechService", "log: onStart called")
            }
            override fun onDone(utteranceId: String) {
                Log.d("AndroidTextToSpeechService", "onDone called with utteranceId: $utteranceId")
                Log.d("AndroidTextToSpeechService", "Audio file generated: $filePath")
                audioFilePathState.value = filePath
                lastGeneratedAudioFilePath = filePath
//                Log.d("AndroidTextToSpeechService","about to attempt to play audio file")
//                playSavedAudioFile(filePath, onStart, onFinish) // Use filePath instead of File(context.cacheDir, "google_tts.mp3").absolutePath
//                Log.d("AndroidTextToSpeechService","just attempted to play audio file")
            }
            override fun onError(utteranceId: String) {
                Log.d("AndroidTextToSpeechService", "log: onError called")
            }
        })
//        textToSpeech.speak(text, TextToSpeech.QUEUE_FLUSH, null, utteranceId)
        lastGeneratedAudioFilePath = filePath
        return filePath
    }
    override fun getAudioFilePath(): String {
        return lastGeneratedAudioFilePath ?: ""
    }
    override fun stop() {
        textToSpeech.stop()
    }
    override fun shutdown() {
        textToSpeech.shutdown()
    }
}
 
``` 
 
 
```ConversationMessage.kt``` 
 
import androidx.compose.runtime.MutableState

data class ConversationMessage(
    val sender: String,
    val message: String,
    val audioFilePath: MutableState<String>
) 
``` 
 
 
```EditSettingsScreen.kt``` 
 
import android.util.Log
import androidx.compose.foundation.layout.*
import androidx.compose.foundation.selection.selectable
import androidx.compose.material.Button
import androidx.compose.material.OutlinedTextField
import androidx.compose.material.Text
import androidx.compose.runtime.Composable
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.unit.dp
import com.example.hello_world.SettingsViewModel
import androidx.compose.runtime.getValue
import androidx.compose.runtime.setValue
import androidx.compose.runtime.mutableStateOf
import androidx.compose.material.RadioButton

import androidx.compose.material.Slider

@Composable
fun EditSettingsScreen(settingsViewModel: SettingsViewModel, onSettingsSaved: () -> Unit, onCancel: () -> Unit) {
    val editedProfile = settingsViewModel.editedProfile.value // Access the value property here

    Column(modifier = Modifier.fillMaxSize()) {
        Text("Edit Settings", modifier = Modifier.padding(16.dp))

        OutlinedTextField(
            value = editedProfile.name, // Access the name property from the value
            onValueChange = { newValue -> settingsViewModel.updateEditedProfileName(newValue) }, // Use newValue instead of it
            label = { Text("Profile Name") },
            modifier = Modifier
                .fillMaxWidth()
                .padding(horizontal = 16.dp)
        )

        OutlinedTextField(
            value = editedProfile.systemMessage.takeIf { it.isNotEmpty() } ?: "I am an AI assistant.",
            onValueChange = { newValue -> settingsViewModel.updateEditedProfileSystemMessage(newValue) },
            label = { Text("System Message") },
            modifier = Modifier
                .fillMaxWidth()
                .padding(horizontal = 16.dp)
        )
        Text("Max Length (20 to 2000)", modifier = Modifier.padding(start = 16.dp, top = 8.dp))
        Slider(
            value = editedProfile.maxLength.toFloat(),
            onValueChange = { newValue -> settingsViewModel.updateEditedProfileMaxLength(newValue.toInt()) },
            valueRange = 20f..2000f,
            steps = 5,
            modifier = Modifier
                .fillMaxWidth()
                .padding(horizontal = 16.dp)
        )
        Text("Temperature", modifier = Modifier.padding(start = 16.dp, top = 8.dp))
        Slider(
            value = editedProfile.temperature.toFloat(),
            onValueChange = { newValue -> settingsViewModel.updateEditedProfileTemperature(newValue.toDouble()) },
            valueRange = 0f..1f,
            steps = 10,
            modifier = Modifier
                .fillMaxWidth()
                .padding(horizontal = 16.dp)
        )
        Text("Frequency Penalty", modifier = Modifier.padding(start = 16.dp, top = 8.dp))
        Slider(
            value = editedProfile.frequencyPenalty.toFloat(),
            onValueChange = { newValue -> settingsViewModel.updateEditedProfileFrequencyPenalty(newValue.toDouble()) },
            valueRange = 0f..1f,
            steps = 10,
            modifier = Modifier
                .fillMaxWidth()
                .padding(horizontal = 16.dp)
        )
        Text("Presence Penalty", modifier = Modifier.padding(start = 16.dp, top = 8.dp))
        Slider(
            value = editedProfile.presencePenalty.toFloat(),
            onValueChange = { newValue -> settingsViewModel.updateEditedProfilePresencePenalty(newValue.toDouble()) },
            valueRange = 0f..1f,
            steps = 10,
            modifier = Modifier
                .fillMaxWidth()
                .padding(horizontal = 16.dp)
        )
        Text("Model", modifier = Modifier.padding(start = 16.dp, top = 8.dp))
        Row(modifier = Modifier.padding(horizontal = 16.dp)) {
            val models = listOf("gpt-3.5-turbo", "gpt-4")
            models.forEach { model ->
                Row(
                    Modifier
                        .padding(end = 16.dp)
                        .selectable(
                            selected = (model == editedProfile.model),
                            onClick = { settingsViewModel.updateEditedProfileModel(model) }
                        )
                ) {
                    RadioButton(
                        selected = (model == editedProfile.model),
                        onClick = { settingsViewModel.updateEditedProfileModel(model) }
                    )
                    Text(
                        text = model,
                        modifier = Modifier.padding(start = 8.dp)
                    )
                }
            }
        }


        Row(
            modifier = Modifier
                .padding(16.dp)
                .fillMaxWidth(),
            horizontalArrangement = Arrangement.SpaceEvenly
        ) {
            Button(onClick = {
                settingsViewModel.saveEditedProfile()
                onSettingsSaved()
                Log.d("EditSettingsScreen", "Save button clicked")
            }) {
                Text("Save")
            }

            Button(onClick = {
                onCancel()
                Log.d("EditSettingsScreen", "Cancel button clicked")
            }) {
                Text("Cancel")
            }
        }
    }
    //display the properties of the profile
    
} 
``` 
 
 
```ElevanLabsTextToSpeechSerivce.kt``` 
 
package com.example.hello_world

import android.media.MediaPlayer
import okhttp3.*
import java.io.IOException
import okhttp3.MediaType.Companion.toMediaType
//import android.os.ParcelFileDescriptor
import java.io.File
import java.io.FileOutputStream
import android.content.Context
import android.util.Log
import androidx.compose.runtime.MutableState
import java.util.UUID


class ElevenLabsTextToSpeechService(
    private val apiKey: String,
    private val voiceId: String,
    private val context: Context
) : TextToSpeechService {
    private var lastGeneratedAudioFilePath: String? = null
    private val client = OkHttpClient()
    override fun speak(text: String, onFinish: (() -> Unit)?, onStart: (() -> Unit)?, audioFilePathState: MutableState<String>): String {
        val fileName = "elevenlabs_tts_${UUID.randomUUID()}.mp3"
        val filePath = File(context.getExternalFilesDir(null), fileName).absolutePath
        val requestBody = createTtsRequestBody(text)
        val request = buildTtsRequest(requestBody)
        client.newCall(request).enqueue(object : Callback {
            override fun onFailure(call: Call, e: IOException) {
                Log.d("ElevenLabsTextToSpeechService", "onFailure called")
                Log.e("ElevenLabsTextToSpeechService", "onFailure called: ${e.message}", e)
            }
            override fun onResponse(call: Call, response: Response) {
                Log.d("ElevenLabsTextToSpeechService", "onResponse called")
                handleTtsResponse(response, filePath, onStart, onFinish, audioFilePathState)
            }
        })
        lastGeneratedAudioFilePath = filePath
        return filePath
    }
    override fun getAudioFilePath(): String {
        return lastGeneratedAudioFilePath ?: ""
    }
    private fun createTtsRequestBody(text: String): RequestBody {
        val json = """
            {
                "text": "$text",
                "voice_settings": {
                    "stability": 0,
                    "similarity_boost": 0
                }
            }
        """.trimIndent()
        Log.d("ElevenLabsTextToSpeechService", "createTtsRequestBody called")
        return RequestBody.create("application/json".toMediaType(), json)
    }
    private fun buildTtsRequest(requestBody: RequestBody): Request {
        Log.d("ElevenLabsTextToSpeechService", "buildTtsRequest called")
        return Request.Builder()
            .url("https://api.elevenlabs.io/v1/text-to-speech/$voiceId")
            .addHeader("accept", "audio/mpeg")
            .addHeader("xi-api-key", apiKey)
            .post(requestBody)
            .build()
    }
    private fun handleTtsResponse(
        response: Response,
        filePath: String,
        onStart: (() -> Unit)?,
        onFinish: (() -> Unit)?,
        audioFilePathState: MutableState<String> // Add this parameter
    ) {
        Log.d("ElevenLabsTextToSpeechService", "handleTtsResponse called")
        if (response.isSuccessful) {
            response.body?.byteStream()?.let { inputStream ->
                FileOutputStream(File(filePath)).use { outputStream ->
                    inputStream.copyTo(outputStream)
                }
                Log.d("ElevenLabsTextToSpeechService", "Audio file saved: $filePath")
                audioFilePathState.value = filePath
//                setupMediaPlayer(filePath, onStart, onFinish)
            }
        } else {
            // Handle the unsuccessful response
            // ...
        }
    }
    //    private fun setupMediaPlayer(filePath: String, onStart: (() -> Unit)?, onFinish: (() -> Unit)?) {
//        Log.d("ElevenLabsTextToSpeechService", "setupMediaPlayer called")
//        val mediaPlayer = MediaPlayer().apply {
//            setDataSource(filePath)
//            setOnPreparedListener {
//                onStart?.invoke()
//                Log.d("ElevenLabsTextToSpeechService", "mediaPlayer onPrepared")
//                start()
//                Log.d("ElevenLabsTextToSpeechService", "mediaPlayer started")
//            }
//            setOnCompletionListener {
//                onFinish?.invoke()
//                Log.d("ElevenLabsTextToSpeechService", "mediaPlayer onCompletion")
//                release()
//                Log.d("ElevenLabsTextToSpeechService", "mediaPlayer released")
//            }
//            prepareAsync()
//            Log.d("ElevenLabsTextToSpeechService", "mediaPlayer preparedAsync")
//        }
//    }
    override fun stop() {
        // Implement stop functionality if needed
    }
    override fun shutdown() {
        // Implement shutdown functionality if needed
    }
}
 
``` 
 
 
```MainActivity.kt``` 
 
package com.example.hello_world
import ConversationMessage
import EditSettingsScreen
import android.Manifest
import android.content.pm.PackageManager
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import androidx.appcompat.app.AppCompatActivity
import android.os.Bundle
import android.util.Log
import android.widget.Toast
import androidx.activity.compose.setContent
import androidx.compose.foundation.layout.Column
import androidx.compose.foundation.layout.fillMaxSize
import androidx.compose.foundation.layout.height
import androidx.compose.foundation.layout.padding
import androidx.compose.foundation.lazy.LazyColumn
import androidx.compose.foundation.lazy.items
import androidx.compose.runtime.Composable
import androidx.compose.runtime.mutableStateListOf
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.foundation.layout.Spacer
import androidx.compose.foundation.layout.fillMaxWidth
import androidx.compose.material3.Button
import androidx.compose.material3.Card
import androidx.compose.material3.Text
import androidx.compose.ui.text.font.FontWeight
import androidx.compose.ui.unit.dp
import androidx.compose.foundation.layout.BoxWithConstraints
import androidx.compose.foundation.layout.Row
import androidx.compose.material.icons.Icons
import androidx.compose.material.icons.filled.AccountBox
import androidx.compose.material.icons.filled.KeyboardArrowLeft
import androidx.compose.material.icons.filled.KeyboardArrowRight
import androidx.compose.material.icons.filled.PlayArrow
import androidx.compose.material3.Icon
import androidx.compose.material3.IconButton
import androidx.compose.runtime.mutableStateOf
import androidx.compose.ui.platform.LocalContext
import androidx.navigation.compose.NavHost
import androidx.navigation.compose.composable
import androidx.navigation.compose.rememberNavController
import androidx.compose.runtime.MutableState


class MainActivity : AppCompatActivity() {
    private var textToSpeechService: TextToSpeechService? = null // Create a text to speech service
    private lateinit var voiceTriggerDetector: VoiceTriggerDetector // Create a voice trigger detector
    private lateinit var openAiApiService: OpenAiApiService // Create an OpenAI API service
    private val RECORD_AUDIO_PERMISSION_REQUEST_CODE = 1 // Create a request code for requesting audio permission
    private val settingsViewModel = SettingsViewModel() // Create a settings view model
    private lateinit var mainViewModel: MainViewModel // Create an main view model

    override fun onCreate(savedInstanceState: Bundle?) { // Called when the activity is starting
        Log.d("MainActivity", "log: MainActivity opened") // Log that the main activity was opened
        super.onCreate(savedInstanceState) // Call the super class onCreate to complete the creation of activity like the view hierarchy
        requestAudioPermission() // Request audio permission
        val textToSpeechServiceState = mutableStateOf<TextToSpeechService>(AndroidTextToSpeechService(this)) // Create the text to speech service, AndroidTextToSpeechService is the default implementation
        openAiApiService = OpenAiApiService("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", settingsViewModel) // Create the OpenAI API service
        mainViewModel = MainViewModel(textToSpeechServiceState, this, settingsViewModel, openAiApiService) // Create the main view model
        voiceTriggerDetector = mainViewModel.voiceTriggerDetector // Create the voice trigger detector
        setContent { // Set the content of the activity to be the UI defined in the composable function
            val navController = rememberNavController() // Create a nav controller
            NavHost(navController, startDestination = "main") { // Create a nav host
                composable("main") { // Create a composable for the main screen
                    MainScreen(mainViewModel, settingsViewModel, { navController.navigate("settings") }, textToSpeechServiceState) // Show the main screen
                } 
                composable("settings") { // Create a composable for the settings screen
                    SettingsScreen(settingsViewModel, { navController.popBackStack() }, navController) // Show the settings screen
                }
                composable("edit-settings") { // Create a composable for the edit settings screen
                    EditSettingsScreen(settingsViewModel, { navController.popBackStack() }, { navController.popBackStack() }) // Show the edit settings screen
                }
            }
        }
    }

    private fun requestAudioPermission() { // Request audio permission
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) == PackageManager.PERMISSION_GRANTED) { // Check if the permission is already granted
            ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.RECORD_AUDIO), RECORD_AUDIO_PERMISSION_REQUEST_CODE) // Request the permission
        }
    }

    override fun onResume() { // When the activity is resumed
        super.onResume() // Call the super class onResume to resume the app
        voiceTriggerDetector.startListening() // Start listening for voice triggers
    }
    override fun onPause() { // When the activity is paused
        super.onPause() // Call the super class onPause to pause the app
        textToSpeechService?.stop() // Stop any ongoing speech
    }

    override fun onDestroy() { // When the activity is destroyed
        super.onDestroy() // Call the super class onDestroy to destroy the app
        textToSpeechService?.shutdown() // Shutdown the text to speech service
    }

    private val conversationMessages = mutableStateListOf<ConversationMessage>() // Create a mutable list of conversation messages
    override fun onRequestPermissionsResult(requestCode: Int, permissions: Array<out String>, grantResults: IntArray) { // When the user responds to the permission request
        super.onRequestPermissionsResult(requestCode, permissions, grantResults) // Call the super class onRequestPermissionsResult to handle the permission request
        if (requestCode == RECORD_AUDIO_PERMISSION_REQUEST_CODE) { // Check if the request code is the same as the one we requested
            if (grantResults.isNotEmpty() && grantResults[0] == PackageManager.PERMISSION_GRANTED) { // Check if the permission was granted
                // Permission was granted
                // Continue with creating the app UI and setting up listeners
            } else {
                // Permission was denied
                // Show a message to the user and close the app
                Toast.makeText(this, "Permission to record audio is required to use this app.", Toast.LENGTH_LONG).show() // Show a toast message to the user
                finish() // Close the app
            }
        }
    }
}

@Composable
fun MediaControls( // Composable for the media controls
    onPlay: () -> Unit, // Function to call when the play button is pressed
    onPause: () -> Unit, // Function to call when the pause button is pressed
    onSeekForward: () -> Unit, // Function to call when the seek forward button is pressed
    onSeekBackward: () -> Unit // Function to call when the seek backward button is pressed
) {
    Row {
        IconButton(onClick = onPlay) { // Create a button for the play button
            Icon(Icons.Filled.PlayArrow, contentDescription = "Play") // Show the play icon
        }
        IconButton(onClick = onPause) { // Create a button for the pause button
            Icon(Icons.Filled.AccountBox, contentDescription = "Pause") // Show the pause icon
        }
        IconButton(onClick = onSeekForward) { // Create a button for the seek forward button
            Icon(Icons.Filled.KeyboardArrowRight, contentDescription = "Seek Forward") // Show the seek forward icon
        }
        IconButton(onClick = onSeekBackward) { // Create a button for the seek backward button
            Icon(Icons.Filled.KeyboardArrowLeft, contentDescription = "Seek Backward") // Show the seek backward icon
        }
    }
}

@Composable
fun MessageCard( // Composable for the message card
    message: ConversationMessage, // The message to show
    onPlayAudio: (String) -> Unit // Function to call when the play audio button is pressed
) {
    Log.d("MessageCard", "Message: $message") 
    Card( // Create a card for the message
        modifier = Modifier // Set the modifier for the card
            .padding(8.dp) // Add padding to the card
            .fillMaxWidth() // Make the card fill the width of the screen
    ) {
        Column( // Create a column for the message
            modifier = Modifier // Set the modifier for the column
                .padding(16.dp) // Add padding to the column
        ) {
            Text(text = message.sender, fontWeight = FontWeight.Bold) // Show the sender of the message
            Spacer(modifier = Modifier.height(4.dp)) // Add a spacer to add some space between the sender and the message
            Text(text = message.message) // Show the message
            Spacer(modifier = Modifier.height(8.dp)) // Add a spacer to add some space between the message and the media controls
            MediaControls( // Show the media controls
                onPlay = { // When the play button is pressed
                    Log.d("MessageCard", "Playing audio from file: ${message.audioFilePath.value}") 
                    onPlayAudio(message.audioFilePath.value) // Call the onPlayAudio function with the audio file path
                },
                onPause = { /* Implement pause functionality in MainViewModel and pass the callback here */ }, // When the pause button is pressed
                onSeekForward = { /* Implement seek forward functionality in MainViewModel and pass the callback here */ }, // When the seek forward button is pressed
                onSeekBackward = { /* Implement seek backward functionality in MainViewModel and pass the callback here */ } // When the seek backward button is pressed
            )
        }
    }
}

@Composable
fun MainScreen( // Composable for the main screen. This is the main screen of the app
    mainViewModel: MainViewModel, // The main view model
    settingsViewModel: SettingsViewModel, // The settings view model
    onSettingsClicked: () -> Unit, // Function to call when the settings button is pressed
    textToSpeechServiceState: MutableState<TextToSpeechService>
) {
    val context = LocalContext.current // Get the current context
    BoxWithConstraints( // Create a box with constraints to get the maximum height of the screen
        modifier = Modifier // Set the modifier for the box
            .fillMaxSize() // Make the box fill the entire screen
            .padding(16.dp) // Add padding to the box
    ) {
        val maxHeight = constraints.maxHeight // Get the maximum height of the screen
        Column(modifier = Modifier.fillMaxSize()) { // Create a column for the main screen
            LazyColumn( // Create a lazy column for the messages
                modifier = Modifier // Set the modifier for the lazy column
                    .weight(1f) // Make the lazy column fill the entire screen
                    .height(((maxHeight.dp - 64.dp).coerceAtLeast(0.dp))) // Set the height of the lazy column to the maximum height of the screen minus the height of the buttons
            ) {
                items(mainViewModel.conversationMessages) { message -> // For each message in the conversation messages
                    MessageCard(message) { audioFilePath -> // Show the message card
                        mainViewModel.mediaPlaybackManager.playAudio(audioFilePath, context) // Play the audio file
                    }
                }
            }
            Spacer(modifier = Modifier.height(16.dp)) // Add a spacer to add some space between the messages and the buttons
            Text( // Show the listening status
                text = if (mainViewModel.isListening) "Listening..." else "Not Listening",  // Show "Listening..." if the app is listening and "Not Listening" if the app is not listening
                modifier = Modifier.align(Alignment.CenterHorizontally) // Align the text to the center horizontally
            ) // Add this line to show the listening status
            Spacer(modifier = Modifier.height(16.dp)) // Add a spacer to add some space between the listening status and the buttons
            Button(
                onClick = { // When the start listening button is pressed
                    if (textToSpeechServiceState.value is AndroidTextToSpeechService) { // If the text to speech service is the Android text to speech service
                        textToSpeechServiceState.value = ElevenLabsTextToSpeechService("82b94d982c1018cb379c0acb629d473c", "TxGEqnHWrfWFTfGW9XjX", context)  // Set the text to speech service to the Eleven Labs text to speech service
                    } else { // If the text to speech service is not the Android text to speech service
                        textToSpeechServiceState.value = AndroidTextToSpeechService(context) // Set the text to speech service to the Android text to speech service
                    }
                },
                modifier = Modifier.align(Alignment.CenterHorizontally) // Align the button to the center horizontally
            ) {
                Text(if (textToSpeechServiceState.value is AndroidTextToSpeechService) "Use Eleven Labs TTS" else "Use Google TTS") // Show "Use Eleven Labs TTS" if the text to speech service is the Android text to speech service and "Use Google TTS" if the text to speech service is not the Android text to speech service
            }
            Button( // Create a button for the start listening button
                onClick = { // When the start listening button is pressed
                    if (mainViewModel.isListening) {  // If the app is listening
                        Log.d("MainActivity", "Stop Listening button clicked")  // Log that the stop listening button was clicked
                        mainViewModel.stopListening() // Stop listening
                    } else {
                        Log.d("MainActivity", "Start Listening button clicked") // Log that the start listening button was clicked
                        mainViewModel.startListening() // Start listening
                    }
                },
                modifier = Modifier.align(Alignment.CenterHorizontally) // Align the button to the center horizontally
            ) {
                Text(if (mainViewModel.isListening) "Stop Listening" else "Start Listening")  // Show "Stop Listening" if the app is listening and "Start Listening" if the app is not listening
            }
            Button( // Create a button for the settings button
                onClick = onSettingsClicked, // When the settings button is pressed
                modifier = Modifier.align(Alignment.CenterHorizontally) // Align the button to the center horizontally
            ) {
                Text("Settings") // Show "Settings"
            }
        }
    }
}
 
``` 
 
 
```MainViewModel.kt``` 
 
package com.example.hello_world
import ConversationMessage
import android.content.Context
import androidx.compose.runtime.mutableStateListOf
import androidx.compose.runtime.mutableStateOf
import androidx.lifecycle.ViewModel
import android.util.Log
import android.os.Handler
import android.os.Looper
import androidx.compose.runtime.MutableState
import androidx.lifecycle.viewModelScope
import kotlinx.coroutines.launch


class MainViewModel(
    private val textToSpeechServiceState: MutableState<TextToSpeechService>,
    private val context: Context,
    private val settingsViewModel: SettingsViewModel,
    private val openAiApiService: OpenAiApiService
) : ViewModel() {
//    private val audioFilePathState = mutableStateOf<String>("") // Add this line
    //    private val openAiApiService = OpenAiApiService("your_api_key_here", settingsViewModel)
    val latestPartialResult = mutableStateOf<String?>(null)
    val _isAppSpeaking = mutableStateOf(false)
    val mediaPlaybackManager: MediaPlaybackManager = AndroidMediaPlaybackManager()
    val isAppSpeaking: Boolean get() = _isAppSpeaking.value
    //    val shouldListenAfterSpeaking = mutableStateOf(true)
    private val mainHandler = Handler(Looper.getMainLooper())
    val voiceTriggerDetector = VoiceTriggerDetector(context, "Hey", this::onTriggerWordDetected, mainHandler, this.latestPartialResult)
    private val _conversationMessages = mutableStateListOf<ConversationMessage>()
    val conversationMessages: List<ConversationMessage> get() = _conversationMessages
    private val _isListening = mutableStateOf(false)
    val isListening: Boolean get() = _isListening.value
    fun startListening() {
        voiceTriggerDetector.startListening()
        _isListening.value = true
        Log.d("MainViewModel", "log: startListening called 1")
    }
    private suspend fun sendUserMessageToOpenAi(userMessage: String) {
        val audioFilePathState = mutableStateOf("")
        // Add user message to the conversation state
        _conversationMessages.add(ConversationMessage("User", userMessage, audioFilePathState))
        val responseText = openAiApiService.sendMessage(_conversationMessages)
        Log.d("MainViewModel", "Received response from OpenAI API: $responseText")
        Log.d("MainViewModel", "User message added with audioFilePathState: $audioFilePathState")
        onAssistantResponse(responseText, audioFilePathState)
        textToSpeechServiceState.value.speak(responseText.replace("\n", " "), onFinish = {
            mainHandler.post {
                _isAppSpeaking.value = false
//                if (_isListening.value) {
                startListening()
                Log.d("MainViewModel", "log: startListening called 2")
//                }
            }
        }, onStart = {
            mainHandler.post {
                stopListening()
                Log.d("MainViewModel", "log: stopListening called 1")
            }
        }, audioFilePathState = _conversationMessages.last().audioFilePath)
        Log.d("MainViewModel", "Updated audioFilePathState: ${audioFilePathState.value}")
        _isAppSpeaking.value = true
    }
    private fun startPeriodicListeningCheck() {
        mainHandler.postDelayed({
            if (_isListening.value && _isAppSpeaking.value) {
//                Log.d("MainViewModel", "log: Periodic check - Restarting listening")
                startListening()
            }
            startPeriodicListeningCheck()
        }, 3000) // Check every 3 seconds
    }
    private fun onAssistantResponse(response: String, audioFilePathState: MutableState<String>) {
        val assistantAudioFilePathState = mutableStateOf("")
        Log.d("MainViewModel", "log: onAssistantResponse called")
        // Add assistant message to the conversation state
        _conversationMessages.add(ConversationMessage("Assistant", response, assistantAudioFilePathState))
        Log.d("MainViewModel", "Assistant message added with audioFilePathState: $assistantAudioFilePathState")
        Log.d("MainViewModel", "log: _conversationMessages added")
    }
    fun stopListening() {
        voiceTriggerDetector.stopListening()
        Log.d("MainViewModel", "log: stopListening called 2")
        _isListening.value = false
    }

    fun onTriggerWordDetected(userMessage: String) { // Add userMessage parameter
        // Add user message to the conversation state
        Log.d("MainViewModel", "log: onTriggerWordDetected called")

        // Stop listening
        voiceTriggerDetector.stopListening() // Replace stopListeningForever() with stopListening()
        Log.d("MainViewModel", "log: stopListening called 3")

        // Send the user message to OpenAI API and process the response
        viewModelScope.launch {
            sendUserMessageToOpenAi(userMessage) // Pass the userMessage parameter here
        }
    }
    init {
        startPeriodicListeningCheck()
    }
}
 
``` 
 
 
```MediaPlaybackManager.kt``` 
 
package com.example.hello_world

import android.content.Context


interface MediaPlaybackManager {
    fun playAudio(filePath: String, context: Context)
    // Add other media control methods as needed
}
 
``` 
 
 
```OpenAiApiResponse.kt``` 
 
package com.example.hello_world
import com.example.hello_world.OpenAiApiResponse

data class OpenAiApiResponse(val choices: List<OpenAiApiChoice>)

data class OpenAiApiChoice(val message: OpenAiApiMessage)

data class OpenAiApiMessage(val role: String, val content: String) 
``` 
 
 
```OpenAiApiService.kt``` 
 
package com.example.hello_world
import ConversationMessage
import android.util.Log
import java.util.Locale
import okhttp3.Call
import okhttp3.Callback
import okhttp3.Response
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.OkHttpClient
import okhttp3.Request
import okhttp3.RequestBody.Companion.toRequestBody
import com.squareup.moshi.Moshi
import com.squareup.moshi.kotlin.reflect.KotlinJsonAdapterFactory
import kotlinx.coroutines.suspendCancellableCoroutine
import java.io.IOException
import java.util.concurrent.TimeUnit
import kotlin.coroutines.resumeWithException


data class OpenAiMessage(val role: String, val content: String)

data class OpenAiApiRequest(
    val messages: List<OpenAiMessage>,
    val temperature: Double,
    val max_tokens: Int,
    val top_p: Int,
    val frequency_penalty: Double,
    val presence_penalty: Double,
    val model: String,
    val stream: Boolean
)

class OpenAiApiService(private val apiKey: String, private val settingsViewModel: SettingsViewModel, private val timeoutInSeconds: Long = 600) {
    private val client = OkHttpClient.Builder()
        .readTimeout(timeoutInSeconds, TimeUnit.SECONDS)
        .writeTimeout(timeoutInSeconds, TimeUnit.SECONDS)
        .connectTimeout(timeoutInSeconds, TimeUnit.SECONDS)
        .build()
    private val moshi = Moshi.Builder().add(KotlinJsonAdapterFactory()).build()

    suspend fun sendMessage(conversationHistory: List<ConversationMessage>): String = suspendCancellableCoroutine { continuation ->
        val currentProfile = settingsViewModel.selectedProfile
        val systemMessage = currentProfile?.systemMessage ?: "you are an ai assistant named jake"
        val messages = mutableListOf(OpenAiMessage("system", systemMessage))

        conversationHistory.forEach { message ->
            messages.add(OpenAiMessage(message.sender.toLowerCase(Locale.ROOT), message.message))
        }

        val selectedProfile = settingsViewModel.selectedProfile

        val requestJson = moshi.adapter(OpenAiApiRequest::class.java).toJson(
            OpenAiApiRequest(
                messages = messages,
                temperature = selectedProfile?.temperature ?: 0.9,
                max_tokens = selectedProfile?.maxLength ?: 100,
                top_p = 1,
                frequency_penalty = selectedProfile?.frequencyPenalty ?: 0.0,
                presence_penalty = selectedProfile?.presencePenalty ?: 0.1,
                model = selectedProfile?.model ?: "gpt-3.5-turbo",
                stream = false
            )
        )
        Log.d("OpenAiApiService", "API Request: $requestJson")
    
        val requestBody = requestJson.toRequestBody("application/json; charset=utf-8".toMediaType())
    
        val request = Request.Builder()
            .url("https://api.openai.com/v1/chat/completions")
            .addHeader("Authorization", "Bearer $apiKey")
            .post(requestBody)
            .build()
    
        val call = client.newCall(request)
    
        call.enqueue(object : Callback {
            override fun onFailure(call: Call, e: IOException) {
                if (continuation.isCancelled) return
                continuation.resumeWithException(e)
            }
    
            override fun onResponse(call: Call, response: Response) {
                if (continuation.isCancelled) return
            
                if (!response.isSuccessful) {
                    continuation.resumeWithException(IOException("Unexpected code $response"))
                } else {
                    val responseBody = response.body?.string()
                    Log.d("OpenAiApiService", "Received JSON: $responseBody") // Add this line to log the received JSON
                    val jsonAdapter = moshi.adapter(OpenAiApiResponse::class.java)
                    val apiResponse = jsonAdapter.fromJson(responseBody)
            
                    continuation.resumeWith(Result.success(apiResponse?.choices?.firstOrNull()?.message?.content ?: ""))
                }
            }
        })
    }
} 
``` 
 
 
```Profile.kt``` 
 
package com.example.hello_world

data class Profile(
    val name: String,
    val systemMessage: String,
    val maxLength: Int,
    val temperature: Double,
    val frequencyPenalty: Double,
    val presencePenalty: Double,
    val model: String
) 
``` 
 
 
```SettingsScreen.kt``` 
 
package com.example.hello_world

import android.util.Log
import androidx.compose.foundation.clickable
import androidx.compose.foundation.layout.Arrangement
import androidx.compose.foundation.layout.Column
import androidx.compose.foundation.layout.Row
import androidx.compose.foundation.layout.Spacer
import androidx.compose.foundation.layout.fillMaxSize
import androidx.compose.foundation.layout.fillMaxWidth
import androidx.compose.foundation.layout.height
import androidx.compose.foundation.layout.padding
import androidx.compose.material3.Button
import androidx.compose.material3.Card
import androidx.compose.material3.Text
import androidx.compose.runtime.Composable
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.draw.shadow
import androidx.compose.ui.unit.dp
import androidx.navigation.NavController

@Composable
fun SettingsScreen(settingsViewModel: SettingsViewModel, onProfileApplied: () -> Unit, navController: NavController) {
    Column(modifier = Modifier.fillMaxSize()) {
        Text("Current Settings", modifier = Modifier.padding(16.dp))
        CurrentSettings(settingsViewModel.selectedProfile)

        Spacer(modifier = Modifier.height(16.dp))

        Text("Select a profile", modifier = Modifier.padding(16.dp))

        settingsViewModel.profiles.forEach { profile ->
            Card(
                modifier = Modifier
                    .padding(8.dp)
                    .fillMaxWidth()
                    .clickable { settingsViewModel.applyProfile(profile) }
                    .shadow(elevation = 4.dp) // Add shadow with the 4.dp elevation
            ) {
                Row(
                    modifier = Modifier
                        .padding(16.dp)
                        .fillMaxWidth(),
                    horizontalArrangement = Arrangement.SpaceBetween,
                    verticalAlignment = Alignment.CenterVertically
                ) {
                    Text(text = profile.name)
                    Button(onClick = {
                        Log.d("SettingsScreen", "Apply button clicked for profile: $profile")
                        settingsViewModel.applyProfile(profile)
                        onProfileApplied()
                    }) {
                        Text("Apply")
                    }
                    Button(
                        onClick = {
                            Log.d("SettingsScreen", "Edit button clicked for profile: $profile")
                            navController.navigate("edit-settings")
                        }
                    ) {
                        Text("Edit")
                    }
                    if (profile !in settingsViewModel.defaultProfiles) {
                        Button(onClick = {
                            Log.d("SettingsScreen", "Delete button clicked for profile: $profile")
                            settingsViewModel.deleteProfile(profile)
                        }) {
                            Text("Delete")
                        }
                    }
                }
            }
        }
    }
}

@Composable
fun CurrentSettings(selectedProfile: Profile?) {
    selectedProfile?.let { profile ->
        Card(
            modifier = Modifier
                .padding(8.dp)
                .fillMaxWidth()
                .shadow(elevation = 4.dp)
        ) {
            Column(
                modifier = Modifier
                    .padding(16.dp)
            ) {
                Text(text = "Model: ${profile.model}")
                Text(text = "System Message: ${profile.systemMessage}")
                Text(text = "Max Length: ${profile.maxLength}")
                Text(text = "Temperature: ${profile.temperature}")
                Text(text = "Frequency Penalty: ${profile.frequencyPenalty}")
                Text(text = "Presence Penalty: ${profile.presencePenalty}")
            }
        }
    }
} 
``` 
 
 
```SettingsViewModel.kt``` 
 
package com.example.hello_world

import android.util.Log
import androidx.compose.runtime.getValue
import androidx.compose.runtime.mutableStateOf
import androidx.compose.runtime.setValue
import androidx.lifecycle.ViewModel


class SettingsViewModel : ViewModel() {

    val defaultProfiles = listOf(
        Profile("Profile 1", "You are an AI assistant named Jake.", 100, 0.9, 0.0, 0.1, "gpt-3.5-turbo"),
        Profile("Profile 2", "You are an AI assistant named Jane.", 150, 0.8, 0.1, 0.2, "gpt-3.5-turbo")
    )
    val editedProfile = mutableStateOf(Profile("", "", 100, 0.9, 0.0, 0.1, "gpt-3.5-turbo"))

    fun updateEditedProfileName(name: String) {
        Log.d("SettingsViewModel", "Profile name updated: $name")
        editedProfile.value = editedProfile.value.copy(name = name)
    }
    var profiles by mutableStateOf(defaultProfiles)
//    var selectedProfile by mutableStateOf<Profile?>(null)
    var selectedProfile by mutableStateOf<Profile?>(defaultProfiles.first())

    fun saveEditedProfile() {
        if (editedProfile.value.name.isNotBlank()) {
            Log.d("SettingsViewModel", "Saving edited profile: ${editedProfile.value}")
            saveCustomProfile(editedProfile.value)
        }
    }

    fun updateEditedProfileSystemMessage(systemMessage: String) {
        Log.d("SettingsViewModel", "System message updated: $systemMessage")
        editedProfile.value = editedProfile.value.copy(systemMessage = systemMessage)
    }

    fun updateEditedProfileMaxLength(maxLength: Int) {
        Log.d("SettingsViewModel", "Max length updated: $maxLength")
        editedProfile.value = editedProfile.value.copy(maxLength = maxLength)
    }

    fun updateEditedProfileTemperature(temperature: Double) {
        Log.d("SettingsViewModel", "Temperature updated: $temperature")
        editedProfile.value = editedProfile.value.copy(temperature = temperature)
    }

    fun updateEditedProfileFrequencyPenalty(frequencyPenalty: Double) {
        Log.d("SettingsViewModel", "Frequency Penalty updated: $frequencyPenalty")
        editedProfile.value = editedProfile.value.copy(frequencyPenalty = frequencyPenalty)
    }

    fun updateEditedProfilePresencePenalty(presencePenalty: Double) {
        Log.d("SettingsViewModel", "Presence Penalty updated: $presencePenalty")
        editedProfile.value = editedProfile.value.copy(presencePenalty = presencePenalty)
    }

    fun updateEditedProfileModel(model: String) {
        Log.d("SettingsViewModel", "Model updated: $model")
        editedProfile.value = editedProfile.value.copy(model = model)
    }

    fun saveCustomProfile(profile: Profile) {
        Log.d("SettingsViewModel", "Saving profile: $profile")
        profiles = profiles.filter { it.name != profile.name } + profile
    }


    fun deleteProfile(profile: Profile) {
        Log.d("SettingsViewModel", "Deleting profile: $profile")
        profiles = profiles.filter { it != profile }
    }

    fun applyProfile(profile: Profile) {
        Log.d("SettingsViewModel", "Applying profile: $profile")
        selectedProfile = profile
    }
} 
``` 
 
 
```TextToSpeechService.kt``` 
 
package com.example.hello_world

import androidx.compose.runtime.MutableState


interface TextToSpeechService {
    fun speak(text: String, onFinish: (() -> Unit)?, onStart: (() -> Unit)?, audioFilePathState: MutableState<String>): String
    fun stop()
    fun getAudioFilePath(): String
    fun shutdown()
}
 
``` 
 
 
```VoiceTriggerDetector.kt``` 
 
package com.example.hello_world
import android.content.Context
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.content.Intent
import android.os.Bundle
import android.util.Log
import android.os.Handler
import android.os.Looper
import androidx.compose.runtime.MutableState


class VoiceTriggerDetector(
    private val context: Context,
    private val triggerWord: String,
    private val onTriggerWordDetected: ((String) -> Unit),
    private val mainHandler: Handler = Handler(Looper.getMainLooper()),
    private val latestPartialResult: MutableState<String?> // Add this line
) : RecognitionListener {
    private val speechRecognizer: SpeechRecognizer = SpeechRecognizer.createSpeechRecognizer(context)
    private var keepListening: Boolean = true

    init {
        speechRecognizer.setRecognitionListener(this)
    }

    fun startListening() {
        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_CALLING_PACKAGE, context.packageName)
            putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, true)
        }
        speechRecognizer.startListening(intent)
    }

    fun stopListening() {
        speechRecognizer.stopListening()
    }

    override fun onReadyForSpeech(params: Bundle) {
        // Handle when the SpeechRecognizer is ready to receive speech input
    }

    override fun onBeginningOfSpeech() {
        // Handle when the user starts speaking
    }

    override fun onRmsChanged(rmsdB: Float) {
        // Handle changes in the received sound level (RMS)
    }

    override fun onBufferReceived(buffer: ByteArray) {
        // Handle more sound data being available
    }

    override fun onEndOfSpeech() {
        // Handle when the user stops speaking
    }

    override fun onError(error: Int) {
        // Handle errors that may occur during speech recognition
    }

    override fun onResults(results: Bundle) {
        val matches = results.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
        Log.d("VoiceTriggerDetector", "Final Results: $matches")
        matches?.let { processResults(it) }
    
        // Restart listening if the trigger word is not detected and the flag is set to keep listening
        if (keepListening) {
            mainHandler.post { startListening() }
        }
    }

    override fun onPartialResults(partialResults: Bundle) {
        val matches = partialResults.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
        Log.d("VoiceTriggerDetector", "Partial Results: $matches")
    
        // Set the latest partial result
        latestPartialResult.value = matches?.firstOrNull()
    
        // Remove the startListening() call from here
    }

    override fun onEvent(eventType: Int, params: Bundle) {
        // Handle any events that may occur during speech recognition
    }



    private fun processResults(matches: ArrayList<String>) {
        for (result in matches) {
            if (result.contains(triggerWord, ignoreCase = true)) {
                // Trigger word detected, handle the event here
                Log.d("VoiceTriggerDetector", "log: Trigger word detected")
                val userMessage = result.replace(Regex("(?i)$triggerWord"), "").trim() // Use a regex to remove the trigger word and extra spaces
                onTriggerWordDetected(userMessage) // Pass the user message here
                break
            }
        }
    }
} 
``` 
 
