this is the codebase: 
 
```OpenAiApiService.kt    
 
package com.example.hello_world


data class OpenAiMessage(val role: String, val content: String)

data class OpenAiApiRequest(
    val messages: List<OpenAiMessage>,
    val temperature: Double,
    val max_tokens: Int,
    val top_p: Int,
    val frequency_penalty: Double,
    val presence_penalty: Double,
    val model: String,
    val stream: Boolean
)

class OpenAiApiService(private val apiKey: String, private val settingsViewModel: SettingsViewModel, private val timeoutInSeconds: Long = 600) {
    private val client = OkHttpClient.Builder()
        .readTimeout(timeoutInSeconds, TimeUnit.SECONDS)
        .writeTimeout(timeoutInSeconds, TimeUnit.SECONDS)
        .connectTimeout(timeoutInSeconds, TimeUnit.SECONDS)
        .build()
    private val moshi = Moshi.Builder().add(KotlinJsonAdapterFactory()).build()

    suspend fun sendMessage(conversationHistory: List<ConversationMessage>): String = suspendCancellableCoroutine { continuation ->
        val currentProfile = settingsViewModel.selectedConfigPack
        val systemMessage = currentProfile?.systemMessage ?: "you are an ai assistant named jake"
        val messages = mutableListOf(OpenAiMessage("system", systemMessage))

        conversationHistory.forEach { message ->
            messages.add(OpenAiMessage(message.sender.toLowerCase(Locale.ROOT), message.message))
        }

        val selectedProfile = settingsViewModel.selectedConfigPack

        val requestJson = moshi.adapter(OpenAiApiRequest::class.java).toJson(
            OpenAiApiRequest(
                messages = messages,
                temperature = selectedProfile?.temperature ?: 0.9,
                max_tokens = selectedProfile?.maxLength ?: 100,
                top_p = 1,
                frequency_penalty = selectedProfile?.frequencyPenalty ?: 0.0,
                presence_penalty = selectedProfile?.presencePenalty ?: 0.1,
                model = selectedProfile?.model ?: "gpt-3.5-turbo",
                stream = false
            )
        )
        Log.d("OpenAiApiService", "API Request: $requestJson")
    
        val requestBody = requestJson.toRequestBody("application/json; charset=utf-8".toMediaType())
    
        val request = Request.Builder()
            .url("https://api.openai.com/v1/chat/completions")
            .addHeader("Authorization", "Bearer $apiKey")
            .post(requestBody)
            .build()
    
        val call = client.newCall(request)
    
        call.enqueue(object : Callback {
            override fun onFailure(call: Call, e: IOException) {
                if (continuation.isCancelled) return
                continuation.resumeWithException(e)
            }
    
            override fun onResponse(call: Call, response: Response) {
                if (continuation.isCancelled) return
            
                if (!response.isSuccessful) {
                    continuation.resumeWithException(IOException("Unexpected code $response"))
                } else {
                    val responseBody = response.body?.string()
//                    Log.d("OpenAiApiService", "Received JSON: $responseBody")
                    val jsonAdapter = moshi.adapter(OpenAiApiResponse::class.java)
                    val apiResponse = jsonAdapter.fromJson(responseBody)
            
                    continuation.resumeWith(Result.success(apiResponse?.choices?.firstOrNull()?.message?.content ?: ""))
                }
            }
        })
    }
 
``` 
 
 
```AndroidMediaPlaybackManager.kt    
 

package com.example.hello_world.services.media_playback


class AndroidMediaPlaybackManager : MediaPlaybackManager {
    var mediaPlayer: MediaPlayer? = null
    private var mediaController: MediaController? = null
    private var currentFilePath: String? = null
    private var playbackPosition: Int = 0

    override fun seekForward() {
        val currentPosition = mediaPlayer?.currentPosition ?: 0
        val newPosition = currentPosition + 10000 // Skip forward by 10 seconds
        mediaPlayer?.seekTo(newPosition)
    }

    override fun seekBackward() {
        val currentPosition = mediaPlayer?.currentPosition ?: 0
        val newPosition = currentPosition - 10000 // Skip backward by 10 seconds
        mediaPlayer?.seekTo(newPosition)
    }
    override fun pause() {
        mediaPlayer?.apply {
            playbackPosition = currentPosition // Save the playback position
            Log.d("AndroidMediaPlaybackManager", "Pausing audio at position: $playbackPosition")
            pause()
        }
    }
    override fun isPlaying(): Boolean {
        return mediaPlayer?.isPlaying ?: false
    }
    override fun playAudio(filePath: String, context: Context, onFinish: (() -> Unit)?) {
        if (filePath.isEmpty()) {
            Toast.makeText(context, "Audio file not loaded", Toast.LENGTH_SHORT).show()
            return
        }
        if (mediaPlayer != null && currentFilePath == filePath) {
            mediaPlayer?.apply {
                Log.d("AndroidMediaPlaybackManager", "Resuming audio at position: $playbackPosition")
                Log.d("AndroidMediaPlaybackManager", "memory address: $this")
                seekTo(playbackPosition) // Set the playback position
                start()
            }
        } else {
            mediaPlayer?.release()
            mediaPlayer = MediaPlayer().apply {
                Log.d("AndroidMediaPlaybackManager", "Playing audio from file: $filePath")
                setDataSource(filePath)
                prepare()
                start()
                setOnCompletionListener {
                    onFinish?.invoke()}
            }
        }
        mediaController?.hide()
        mediaController = MediaController(context)
        mediaController?.setMediaPlayer(object : MediaController.MediaPlayerControl {
            private var isPaused = false
            override fun start() {
                if (isPaused) {
                    mediaPlayer?.start()
                    isPaused = false
                }
            }

            override fun pause() {
                if (mediaPlayer?.isPlaying == true) {
                    mediaPlayer?.pause()
                    isPaused = true
                }
            }
            // Implement other required methods
            override fun getDuration(): Int = mediaPlayer?.duration ?: 0
            override fun getCurrentPosition(): Int = mediaPlayer?.currentPosition ?: 0
            override fun getBufferPercentage(): Int = 0
            override fun isPlaying(): Boolean = mediaPlayer?.isPlaying ?: false
            override fun seekTo(position: Int) {
                mediaPlayer?.seekTo(position)
            }
            override fun canPause(): Boolean {
                // Return true if your media player can pause, otherwise return false
                return true
            }
            override fun getAudioSessionId(): Int {
                // Return the audio session ID of your media player or 0 if not available
                return mediaPlayer?.audioSessionId ?: 0
            }
            override fun canSeekBackward(): Boolean {
                // Return true if your media player can seek backward, otherwise return false
                return true
            }
            override fun canSeekForward(): Boolean {
                // Return true if your media player can seek forward, otherwise return false
                return true
            }
        })
        mediaController?.show()
    }
}
 
``` 
 
 
```MediaPlaybackManager.kt    
 
package com.example.hello_world.services.media_playback



interface MediaPlaybackManager {
    fun playAudio(filePath: String, context: Context, onFinish: (() -> Unit)? = null)
    fun isPlaying(): Boolean
    fun pause()
    // Add other media control methods as needed
    fun seekForward()
    fun seekBackward()
}
 
``` 
 
 
```VoiceTriggerDetector.kt    
 
package com.example.hello_world.services.speech_to_text


class VoiceTriggerDetector(
    private val context: Context,
    private val triggerWord: String,
    private val onTriggerWordDetected: ((String) -> Unit),
    private val mainHandler: Handler = Handler(Looper.getMainLooper()),
    private val latestPartialResult: MutableState<String?> 
) : RecognitionListener {
    private val speechRecognizer: SpeechRecognizer = SpeechRecognizer.createSpeechRecognizer(context)
    private var keepListening: Boolean = true

    init {
        speechRecognizer.setRecognitionListener(this)
    }

    fun startListening() {
        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_CALLING_PACKAGE, context.packageName)
            putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, true)
        }
        speechRecognizer.startListening(intent)
    }

    fun stopListening() {
        speechRecognizer.stopListening()
        Log.d("VoiceTriggerDetector", "log: within the stoplistening function, speechRecognizer.stopListening() was just called")
    }

    override fun onReadyForSpeech(params: Bundle) {
        // Handle when the SpeechRecognizer is ready to receive speech input
    }

    override fun onBeginningOfSpeech() {
        // Handle when the user starts speaking
    }

    override fun onRmsChanged(rmsdB: Float) {
        // Handle changes in the received sound level (RMS)
    }

    override fun onBufferReceived(buffer: ByteArray) {
        // Handle more sound data being available
    }

    override fun onEndOfSpeech() {
        // Handle when the user stops speaking
    }

    override fun onError(error: Int) {
        // Handle errors that may occur during speech recognition
    }

    override fun onResults(results: Bundle) {
        val matches = results.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
        Log.d("VoiceTriggerDetector", "Final Results: $matches")
        matches?.let { processResults(it) }
    
        // Restart listening if the trigger word is not detected and the flag is set to keep listening
        if (keepListening) {
            mainHandler.post { startListening() }
        }
    }

    override fun onPartialResults(partialResults: Bundle) {
        val matches = partialResults.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
//        Log.d("VoiceTriggerDetector", "Partial Results: $matches")
        Toast.makeText(context, "Partial Results: $matches", Toast.LENGTH_SHORT).show()
    
        // Set the latest partial result
        latestPartialResult.value = matches?.firstOrNull()
    
        // Remove the startListening() call from here
    }

    override fun onEvent(eventType: Int, params: Bundle) {
        // Handle any events that may occur during speech recognition
    }



    private fun processResults(matches: ArrayList<String>) {
        for (result in matches) {
            if (result.contains(triggerWord, ignoreCase = true)) {
                // Trigger word detected, handle the event here
                Log.d("VoiceTriggerDetector", "log: Trigger word detected")
                val userMessage = result.replace(Regex("(?i)$triggerWord"), "").trim() // Use a regex to remove the trigger word and extra spaces
                onTriggerWordDetected(userMessage) // Pass the user message here
                break
            }
        }
    }
 
``` 
 
 
```AndroidTextToSpeechService.kt    
 
package com.example.hello_world.services.text_to_speech



class AndroidTextToSpeechService(
    private val context: Context,
    override val mediaPlaybackManager: MediaPlaybackManager,
    private val onPlaybackFinished: () -> Unit
) : TextToSpeechService, TextToSpeech.OnInitListener {
    private var lastGeneratedAudioFilePath: String? = null
    private var textToSpeech: TextToSpeech = TextToSpeech(context, this)
    override fun onInit(status: Int) {
        if (status == TextToSpeech.SUCCESS) {
            val result = textToSpeech.setLanguage(Locale.getDefault())
            if (result == TextToSpeech.LANG_MISSING_DATA || result == TextToSpeech.LANG_NOT_SUPPORTED) {
                // Handle the case where the default language data or the language itself is not supported
            }
        } else {
            // Handle the case where TextToSpeech initialization failed
        }
    }

    override fun renderSpeech(text: String, onFinish: (() -> Unit)?, onStart: (() -> Unit)?, audioFilePathState: MutableState<String>): String {
        val utteranceId = UUID.randomUUID().toString()
//        Log.d("AndroidTextToSpeechService", "synthesizeToFile called with utteranceId: $utteranceId")
        val uniqueFileName = "google_tts_${UUID.randomUUID()}.mp3"
        val filePath = File(context.getExternalFilesDir(null), uniqueFileName).absolutePath

        textToSpeech.synthesizeToFile(text, null, File(filePath), UUID.randomUUID().toString())
        textToSpeech.setOnUtteranceProgressListener(object : UtteranceProgressListener() {
            override fun onStart(utteranceId: String) {
                onStart?.invoke()
                Log.d("AndroidTextToSpeechService", "log: the onStart method with the speak function has been called")
            }
            override fun onDone(utteranceId: String) {
//                Log.d("AndroidTextToSpeechService", "onDone called with utteranceId: $utteranceId")
                Log.d("AndroidTextToSpeechService", "Audio file generated: $filePath")
                audioFilePathState.value = filePath
                lastGeneratedAudioFilePath = filePath
//                Log.d("AndroidTextToSpeechService","about to attempt to play audio file")
//                playSavedAudioFile(filePath, onStart, onFinish) // Use filePath instead of File(context.cacheDir, "google_tts.mp3").absolutePath
//                Log.d("AndroidTextToSpeechService","just attempted to play audio file")
                mediaPlaybackManager.playAudio(filePath, context, onFinish = onPlaybackFinished)
            }
            override fun onError(utteranceId: String) {
                Log.d("AndroidTextToSpeechService", "log: onError called")
            }
        })
//        textToSpeech.speak(text, TextToSpeech.QUEUE_FLUSH, null, utteranceId)
        lastGeneratedAudioFilePath = filePath
        return filePath
    }
    override fun getAudioFilePath(): String {
        return lastGeneratedAudioFilePath ?: ""
    }
    override fun stop() {
        textToSpeech.stop()
    }
    override fun shutdown() {
        textToSpeech.shutdown()
    }
}
 
``` 
 
 
```ElevenLabsTextToSpeechService.kt    
 
package com.example.hello_world.services.text_to_speech


class ElevenLabsTextToSpeechService(
    private val apiKey: String,
    private val voiceId: String,
    private val context: Context,
    override val mediaPlaybackManager: MediaPlaybackManager,
    private val onPlaybackFinished: () -> Unit
) : TextToSpeechService {
    private var lastGeneratedAudioFilePath: String? = null
    private val client = OkHttpClient()
    override fun renderSpeech(text: String, onFinish: (() -> Unit)?, onStart: (() -> Unit)?, audioFilePathState: MutableState<String>): String {
        val fileName = "elevenlabs_tts_${UUID.randomUUID()}.mp3"
        val filePath = File(context.getExternalFilesDir(null), fileName).absolutePath
        val requestBody = createTtsRequestBody(text)
        val request = buildTtsRequest(requestBody)
        client.newCall(request).enqueue(object : Callback {
            override fun onFailure(call: Call, e: IOException) {
                Log.d("ElevenLabsTextToSpeechService", "onFailure called")
                Log.e("ElevenLabsTextToSpeechService", "onFailure called: ${e.message}", e)
            }
            override fun onResponse(call: Call, response: Response) {
                Log.d("ElevenLabsTextToSpeechService", "onResponse called")
                handleTtsResponse(response, filePath, onStart, onFinish, audioFilePathState)
            }
        })
        lastGeneratedAudioFilePath = filePath
        return filePath
    }
    override fun getAudioFilePath(): String {
        return lastGeneratedAudioFilePath ?: ""
    }
    private fun createTtsRequestBody(text: String): RequestBody {
        val json = """
            {
                "text": "$text",
                "voice_settings": {
                    "stability": 0,
                    "similarity_boost": 0
                }
            }
        """.trimIndent()
        Log.d("ElevenLabsTextToSpeechService", "createTtsRequestBody called")
        return RequestBody.create("application/json".toMediaType(), json)
    }
    private fun buildTtsRequest(requestBody: RequestBody): Request {
        Log.d("ElevenLabsTextToSpeechService", "buildTtsRequest called")
        return Request.Builder()
            .url("https://api.elevenlabs.io/v1/text-to-speech/$voiceId")
            .addHeader("accept", "audio/mpeg")
            .addHeader("xi-api-key", apiKey)
            .post(requestBody)
            .build()
    }
    private fun handleTtsResponse(
        response: Response,
        filePath: String,
        onStart: (() -> Unit)?,
        onFinish: (() -> Unit)?, // Add this line
        audioFilePathState: MutableState<String>
    ) {
        Log.d("ElevenLabsTextToSpeechService", "handleTtsResponse called")
        if (response.isSuccessful) {
            response.body?.byteStream()?.let { inputStream ->
                FileOutputStream(File(filePath)).use { outputStream ->
                    inputStream.copyTo(outputStream)
                }
                Log.d("ElevenLabsTextToSpeechService", "Audio file saved: $filePath")
                audioFilePathState.value = filePath
                mediaPlaybackManager.playAudio(filePath, context, onFinish = {
                    onFinish?.invoke()
                    onPlaybackFinished()
//                    voiceTriggerDetector.stopListening()
                    Log.d(
                        "ElevenLabsTextToSpeechService", "\nonFinish?.invoke()\n" +
                                "            onPlaybackFinished()\nwas just called"
                    )
                }) // Pass onFinish here
            }
        } else {
            // Handle the unsuccessful response
            // ...
        }
        mediaPlaybackManager.playAudio(filePath, context, onFinish = {
            onFinish?.invoke()
            onPlaybackFinished()
            Log.d(
                "ElevenLabsTextToSpeechService", "\nonFinish?.invoke()\n" +
                        "            onPlaybackFinished()\nwas just called"
            )
        }) // Pass onFinish here
    }

    override fun stop() {
        // Implement stop functionality if needed
    }
    override fun shutdown() {
        // Implement shutdown functionality if needed
    }
 
``` 
 
 
```TextToSpeechService.kt    
 
package com.example.hello_world.services.text_to_speech



interface TextToSpeechService {
    val mediaPlaybackManager: MediaPlaybackManager
    fun renderSpeech(text: String, onFinish: (() -> Unit)?, onStart: (() -> Unit)?, audioFilePathState: MutableState<String>): String
    fun stop()
    fun getAudioFilePath(): String
    fun shutdown()
}
 
``` 
 
